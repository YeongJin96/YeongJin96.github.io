<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>SimCLR_train code | YeongJin </title> <meta name="author" content="YeongJin "> <meta name="description" content="SimCLR 모델을 학습할 때 사용한 코드입니다."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://yeongjin96.github.io/blog/2023/SimCLR_train/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">YeongJin </span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">SimCLR_train code</h1> <p class="post-meta">January 18, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/simclr"> <i class="fas fa-hashtag fa-sm"></i> SimCLR</a>     ·   <a href="/blog/category/code"> <i class="fas fa-tag fa-sm"></i> code</a>   </p> </header> <article class="post-content"> <p>SimCLR 학습 코드입니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torchvision</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">os</span>
</code></pre></div></div> <p>torchvision의 transforms을 사용해서, 이미지 Augmentation을 생성하는 클래스입니다.</p> <p>train_transform은 train용 augmentation으로, resize&amp;crop, flip, color_jitter를 사용했고, 0.2의 확률로 grayscale로 변환한 뒤, 텐서로 만들고, SimCLR은 1개의 이미지당 2개의 augmentation 이미지를 필요로 하므로, 같은 transform으로 두개의 이미지를 return합니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TransformsSimCLR</span><span class="p">:</span>
    <span class="s">"""
    A stochastic data augmentation module that transforms any given data example randomly
    resulting in two correlated views of the same example,
    denoted x ̃i and x ̃j, which we consider as a positive pair.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">color_jitter</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ColorJitter</span><span class="p">(</span>
            <span class="mf">0.8</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">s</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">),</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">RandomHorizontalFlip</span><span class="p">(),</span>  <span class="c1"># with 0.5 probability
</span>                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">RandomApply</span><span class="p">([</span><span class="n">color_jitter</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">),</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">test_transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">),</span>
                <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
            <span class="p">]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">train_transform</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">self</span><span class="p">.</span><span class="nf">train_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>Github에는 yaml파일로 parameters를 불러오는 방식을 사용했지만, yaml파일 없이 코드실행을 위해 따로 parameters를 정의했습니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="n">ImageFolder</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-06</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s">"../save_models"</span>
<span class="n">current_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.5</span>
</code></pre></div></div> <p>Dataset정의</p> <p>가장 위에 정의했던 transfrom클래스를 사용해 이미지들을 augmentation후, data_loader를 만듭니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'../data/PNU_all'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">TransformsSimCLR</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">input_size</span><span class="p">))</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                           <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                           <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>pytorch에 정의되어있는 resnet18과 resnet50을 입력에 따라 불러옵니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_resnet</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">resnets</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"resnet18"</span><span class="p">:</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="n">pretrained</span><span class="p">),</span>
        <span class="s">"resnet50"</span><span class="p">:</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="n">pretrained</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">resnets</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
        <span class="k">raise</span> <span class="nc">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> is not a valid ResNet version"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resnets</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</code></pre></div></div> <p>입력으로 받은것을 그대로 return해주는 Identity클래스 입니다. (ResNet의 skip connection)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Identity</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Identity</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div> <p>LARS Optimizer입니다. (설명 링크)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
LARS: Layer-wise Adaptive Rate Scaling
Converted from TensorFlow to PyTorch
https://github.com/google-research/simclr/blob/master/lars_optimizer.py
"""</span>

<span class="kn">from</span> <span class="n">torch.optim.optimizer</span> <span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">required</span>
<span class="kn">import</span> <span class="n">re</span>

<span class="n">EETA_DEFAULT</span> <span class="o">=</span> <span class="mf">0.001</span>


<span class="k">class</span> <span class="nc">LARS</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="s">"""
    Layer-wise Adaptive Rate Scaling for large batch training.
    Introduced by "Large Batch Training of Convolutional Networks" by Y. You,
    I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">params</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">required</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">use_nesterov</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">exclude_from_weight_decay</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">exclude_from_layer_adaptation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">classic_momentum</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">eeta</span><span class="o">=</span><span class="n">EETA_DEFAULT</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="s">"""Constructs a LARSOptimizer.
        Args:
        lr: A `float` for learning rate.
        momentum: A `float` for momentum.
        use_nesterov: A 'Boolean' for whether to use nesterov momentum.
        weight_decay: A `float` for weight decay.
        exclude_from_weight_decay: A list of `string` for variable screening, if
            any of the string appears in a variable's name, the variable will be
            excluded for computing weight decay. For example, one could specify
            the list like ['batch_normalization', 'bias'] to exclude BN and bias
            from weight decay.
        exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but
            for layer adaptation. If it is None, it will be defaulted the same as
            exclude_from_weight_decay.
        classic_momentum: A `boolean` for whether to use classic (or popular)
            momentum. The learning rate is applied during momeuntum update in
            classic momentum, but after momentum for popular momentum.
        eeta: A `float` for scaling of learning rate when computing trust ratio.
        name: The name for the scope.
        """</span>

        <span class="n">self</span><span class="p">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span>
            <span class="n">use_nesterov</span><span class="o">=</span><span class="n">use_nesterov</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">exclude_from_weight_decay</span><span class="o">=</span><span class="n">exclude_from_weight_decay</span><span class="p">,</span>
            <span class="n">exclude_from_layer_adaptation</span><span class="o">=</span><span class="n">exclude_from_layer_adaptation</span><span class="p">,</span>
            <span class="n">classic_momentum</span><span class="o">=</span><span class="n">classic_momentum</span><span class="p">,</span>
            <span class="n">eeta</span><span class="o">=</span><span class="n">eeta</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nf">super</span><span class="p">(</span><span class="n">LARS</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="n">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="n">self</span><span class="p">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="n">self</span><span class="p">.</span><span class="n">use_nesterov</span> <span class="o">=</span> <span class="n">use_nesterov</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classic_momentum</span> <span class="o">=</span> <span class="n">classic_momentum</span>
        <span class="n">self</span><span class="p">.</span><span class="n">eeta</span> <span class="o">=</span> <span class="n">eeta</span>
        <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_weight_decay</span> <span class="o">=</span> <span class="n">exclude_from_weight_decay</span>
        <span class="c1"># exclude_from_layer_adaptation is set to exclude_from_weight_decay if the
</span>        <span class="c1"># arg is None.
</span>        <span class="k">if</span> <span class="n">exclude_from_layer_adaptation</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_layer_adaptation</span> <span class="o">=</span> <span class="n">exclude_from_layer_adaptation</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_layer_adaptation</span> <span class="o">=</span> <span class="n">exclude_from_weight_decay</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">closure</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">epoch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">epoch</span>
            <span class="n">self</span><span class="p">.</span><span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">weight_decay</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">"weight_decay"</span><span class="p">]</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">"momentum"</span><span class="p">]</span>
            <span class="n">eeta</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">"eeta"</span><span class="p">]</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">"lr"</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s">"params"</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="n">param</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">data</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>

                <span class="n">param_state</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>

                <span class="c1"># TODO: get param names
</span>                <span class="c1"># if self._use_weight_decay(param_name):
</span>                <span class="n">grad</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight_decay</span> <span class="o">*</span> <span class="n">param</span>

                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">classic_momentum</span><span class="p">:</span>
                    <span class="n">trust_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>

                    <span class="c1"># TODO: get param names
</span>                    <span class="c1"># if self._do_layer_adaptation(param_name):
</span>                    <span class="n">w_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
                    <span class="n">g_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>

                    <span class="n">device</span> <span class="o">=</span> <span class="n">g_norm</span><span class="p">.</span><span class="nf">get_device</span><span class="p">()</span>
                    <span class="n">trust_ratio</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span>
                        <span class="n">w_norm</span><span class="p">.</span><span class="nf">ge</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span>
                            <span class="n">g_norm</span><span class="p">.</span><span class="nf">ge</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                            <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">eeta</span> <span class="o">*</span> <span class="n">w_norm</span> <span class="o">/</span> <span class="n">g_norm</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                        <span class="p">),</span>
                        <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                    <span class="p">).</span><span class="nf">item</span><span class="p">()</span>

                    <span class="n">scaled_lr</span> <span class="o">=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">trust_ratio</span>
                    <span class="k">if</span> <span class="s">"momentum_buffer"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param_state</span><span class="p">:</span>
                        <span class="n">next_v</span> <span class="o">=</span> <span class="n">param_state</span><span class="p">[</span><span class="s">"momentum_buffer"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span>
                            <span class="n">p</span><span class="p">.</span><span class="n">data</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">next_v</span> <span class="o">=</span> <span class="n">param_state</span><span class="p">[</span><span class="s">"momentum_buffer"</span><span class="p">]</span>

                    <span class="n">next_v</span><span class="p">.</span><span class="nf">mul_</span><span class="p">(</span><span class="n">momentum</span><span class="p">).</span><span class="nf">add_</span><span class="p">(</span><span class="n">scaled_lr</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">use_nesterov</span><span class="p">:</span>
                        <span class="n">update</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="n">next_v</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">scaled_lr</span> <span class="o">*</span> <span class="n">grad</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">update</span> <span class="o">=</span> <span class="n">next_v</span>

                    <span class="n">p</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">add_</span><span class="p">(</span><span class="o">-</span><span class="n">update</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="nb">NotImplementedError</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">_use_weight_decay</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">param_name</span><span class="p">):</span>
        <span class="s">"""Whether to use L2 weight decay for `param_name`."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">weight_decay</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_weight_decay</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_weight_decay</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">_do_layer_adaptation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">param_name</span><span class="p">):</span>
        <span class="s">"""Whether to do layer-wise learning rate adaptation for `param_name`."""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_layer_adaptation</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">exclude_from_layer_adaptation</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="bp">True</span>
</code></pre></div></div> <p>SimCLR 모델입니다.</p> <p>encoder는 feature를 추출하기 위한 CNN based 모델입니다.</p> <p>n_features는 MLP(projector)레이어의 parameter로 사용되었습니다.</p> <p>projectrion_dim은 최종적으로 추출할 feature의 갯수입니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SimCLR</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    We opt for simplicity and adopt the commonly used ResNet (He et al., 2016) to obtain hi = f(x ̃i) = ResNet(x ̃i) where hi ∈ Rd is the output after the average pooling layer.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">,</span> <span class="n">n_features</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">SimCLR</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>

        <span class="c1"># Replace the fc layer with an Identity function
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="nc">Identity</span><span class="p">()</span>

        <span class="c1"># We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">projector</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">):</span>
        <span class="n">h_i</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span>
        <span class="n">h_j</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x_j</span><span class="p">)</span>

        <span class="n">z_i</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">projector</span><span class="p">(</span><span class="n">h_i</span><span class="p">)</span>
        <span class="n">z_j</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">projector</span><span class="p">(</span><span class="n">h_j</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h_i</span><span class="p">,</span> <span class="n">h_j</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">"Adam"</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>  <span class="c1"># TODO: LARS
</span>    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">"LARS"</span><span class="p">:</span>
        <span class="c1"># optimized using LARS with linear learning rate scaling
</span>        <span class="c1"># (i.e. LearningRate = 0.3 × BatchSize/256) and weight decay of 10−6.
</span>        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="mi">256</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nc">LARS</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">exclude_from_weight_decay</span><span class="o">=</span><span class="p">[</span><span class="s">"batch_normalization"</span><span class="p">,</span> <span class="s">"bias"</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># "decay the learning rate with the cosine decay schedule without restarts"
</span>        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">CosineAnnealingLR</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nb">NotImplementedError</span>

    <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span>


<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">current_epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="s">"checkpoint_{}.tar"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">current_epoch</span><span class="p">))</span>

    <span class="c1"># To save a DataParallel model generically, save the model.module.state_dict().
</span>    <span class="c1"># This way, you have the flexibility to load the model any way you want to any device you want.
</span>    <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">DataParallel</span><span class="p">):</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">module</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">out</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">out</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.distributed</span> <span class="k">as</span> <span class="n">dist</span>


<span class="k">class</span> <span class="nc">GatherLayer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="s">"""Gather tensors from all process, supporting backward propagation."""</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">ctx</span><span class="p">.</span><span class="nf">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="nf">get_world_size</span><span class="p">())]</span>
        <span class="n">dist</span><span class="p">.</span><span class="nf">all_gather</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="o">*</span><span class="n">grads</span><span class="p">):</span>
        <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">grad_out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="n">dist</span><span class="p">.</span><span class="nf">get_rank</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">grad_out</span>
</code></pre></div></div> <p>Augmentation된 이미지 쌍(pair)의 similarity계산을 위한 NT_Xent loss함수 입니다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.distributed</span> <span class="k">as</span> <span class="n">dist</span>

<span class="k">class</span> <span class="nc">NT_Xent</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">NT_Xent</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="n">self</span><span class="p">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">world_size</span>

        <span class="n">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mask_correlated_samples</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s">"sum"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">similarity_f</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mask_correlated_samples</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">world_size</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">fill_diagonal_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">):</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">world_size</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">world_size</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">):</span>
        <span class="s">"""
        We do not sample negative examples explicitly.
        Instead, given a positive pair, similar to (Chen et al., 2017), we treat the other 2(N − 1) augmented examples within a minibatch as negative examples.
        """</span>
        <span class="n">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">world_size</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">GatherLayer</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">sim</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">similarity_f</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">z</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">sim_i_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">world_size</span><span class="p">)</span>
        <span class="n">sim_j_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">world_size</span><span class="p">)</span>

        <span class="c1"># We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN
</span>        <span class="n">positive_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">sim_i_j</span><span class="p">,</span> <span class="n">sim_j_i</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">negative_samples</span> <span class="o">=</span> <span class="n">sim</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">positive_samples</span><span class="p">.</span><span class="n">device</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">positive_samples</span><span class="p">,</span> <span class="n">negative_samples</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="n">N</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="n">writer</span> <span class="o">=</span> <span class="nc">SummaryWriter</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">((</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">x_i</span><span class="p">.</span><span class="nf">cuda</span><span class="p">(</span><span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">x_j</span> <span class="o">=</span> <span class="n">x_j</span><span class="p">.</span><span class="nf">cuda</span><span class="p">(</span><span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># positive pair, with encoding
</span>        <span class="n">h_i</span><span class="p">,</span> <span class="n">h_j</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Step [</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s">]</span><span class="se">\t</span><span class="s"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="s">"Loss/train_epoch"</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">global_step</span><span class="p">)</span>
        <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">global_step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">loss_epoch</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resnet</span> <span class="o">=</span> <span class="s">"resnet50"</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="nf">get_resnet</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">in_features</span>  <span class="c1"># get dimensions of fc layer
</span>
<span class="n">projection_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">SimCLR</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="s">"cuda"</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="s">"cpu"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="nf">load_optimizer</span><span class="p">(</span><span class="s">"LARS"</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span> <span class="o">=</span> <span class="nc">NT_Xent</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">global_step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">current_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"lr"</span><span class="p">]</span>
    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">scheduler</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">save_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">current_epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        
    <span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="s">"Loss/train"</span><span class="p">,</span> <span class="n">loss_epoch</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="s">"Misc/learning_rate"</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s">"Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">]</span><span class="se">\t</span><span class="s"> Loss: </span><span class="si">{</span><span class="n">loss_epoch</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="se">\t</span><span class="s"> lr: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="p">)</span>
    <span class="n">current_epoch</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="nf">save_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">current_epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step [0/192]	 Loss: 5.547216415405273
Step [50/192]	 Loss: 5.5168609619140625
Step [100/192]	 Loss: 5.466494083404541
Step [150/192]	 Loss: 5.5113701820373535
Epoch [0/500]	 Loss: 5.47970977673928	 lr: 0.15
Step [0/192]	 Loss: 5.416123390197754
Step [50/192]	 Loss: 5.365357398986816
Step [100/192]	 Loss: 5.415189266204834
Step [150/192]	 Loss: 5.289378643035889
Epoch [1/500]	 Loss: 5.405081287026405	 lr: 0.15
Step [0/192]	 Loss: 5.412885665893555
Step [50/192]	 Loss: 5.288458347320557
Step [100/192]	 Loss: 5.321774005889893
Step [150/192]	 Loss: 5.202507972717285
Epoch [2/500]	 Loss: 5.278357977668445	 lr: 0.14999
Step [0/192]	 Loss: 5.205842971801758
Step [50/192]	 Loss: 5.146916389465332
Step [100/192]	 Loss: 5.040021896362305
Step [150/192]	 Loss: 5.046496391296387
Epoch [3/500]	 Loss: 5.109636095662911	 lr: 0.14999
Step [0/192]	 Loss: 5.132671356201172
Step [50/192]	 Loss: 4.919950008392334
Step [100/192]	 Loss: 5.0143327713012695
Step [150/192]	 Loss: 4.902953147888184
Epoch [4/500]	 Loss: 4.947697018583615	 lr: 0.14998
Step [0/192]	 Loss: 4.82228946685791
Step [50/192]	 Loss: 4.764313220977783
Step [100/192]	 Loss: 4.924652576446533
Step [150/192]	 Loss: 4.818438529968262
'
'
'
Epoch [495/500]	 Loss: 3.9043560971816382	 lr: 4e-05
Step [0/192]	 Loss: 3.893375873565674
Step [50/192]	 Loss: 3.9129462242126465
Step [100/192]	 Loss: 3.8850409984588623
Step [150/192]	 Loss: 3.884953498840332
Epoch [496/500]	 Loss: 3.903852423032125	 lr: 2e-05
Step [0/192]	 Loss: 3.869290828704834
Step [50/192]	 Loss: 3.9251136779785156
Step [100/192]	 Loss: 3.8720123767852783
Step [150/192]	 Loss: 3.9006035327911377
Epoch [497/500]	 Loss: 3.9030883188048997	 lr: 1e-05
Step [0/192]	 Loss: 3.949983835220337
Step [50/192]	 Loss: 3.929286479949951
Step [100/192]	 Loss: 3.900035858154297
Step [150/192]	 Loss: 3.9218673706054688
Epoch [498/500]	 Loss: 3.9071918639043965	 lr: 1e-05
Step [0/192]	 Loss: 3.8706607818603516
Step [50/192]	 Loss: 3.879091501235962
Step [100/192]	 Loss: 3.887544870376587
Step [150/192]	 Loss: 3.8865678310394287
Epoch [499/500]	 Loss: 3.903093626101812	 lr: 0.0
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 YeongJin . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>